[project]
name = "LLM-Scoring-Engine"
version = "0.6.0"
description = "A comprehensive system for evaluating and scoring large language models based on multiple criteria."
dependencies = [
    "typing_extensions>=4.0.0",
    "argparse>=1.4.0",
    "huggingface-hub>=0.20.0",
    "pandas",
    "plotly",
    "Jinja2"
]
requires-python = ">=3.11"

[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

[project.optional-dependencies]
dev = [
    "pytest>=7.0.0",
    "pytest-cov>=4.0.0",
    "black>=23.0.0",
    "flake8>=6.0.0"
]
fill-benchmark-pipeline = [
    "requests>=2.31.0",
    "pandas>=2.0.0",
    "tqdm>=4.65.0",
    "python-dotenv>=1.0.0",
    "pydantic>=2.0.0",
    "pyyaml>=6.0.0",
    "tenacity>=8.0.0"
] 

[tool.hatch.build.targets.wheel]
packages = ["model_scoring"] 
